% !TEX root = userguide_en.tex
%----------------------------------------------------------
\chapter{ Algorithm}
\label{Ch:algorithm}
\section{Lanczos method}
\label{Ch:Lanczos}
\subsection{Details of Lanczos method}
Some parts of this section are based on the manual
of TITPACK~\cite{titpack} and the textbook published by M. Sugihara and 
K. Murota~\cite{SugiharaMurota_en}(these references are written in Japanese).

In the Lanczos method, by successively operating the Hamiltonian 
to the initial vector, we obtain the accurate eigenvalues around
the maximum and minimum eigenvalues and associated eigenvectors.  
Because we can perform the Lanczos method by using only two
vectors, the dimensions of which are the dimensions of the total Hilbert space\footnote{In $\HPhi$, 
to reduce the numerical cost,
we use some additional vectors;
a vector for accumulating the 
real-space diagonal elements of the Hamiltonian and
a vector for specifying the given $S_{z}$ space and given particle space.
The dimension of these vectors is that of the Hilbert space.},
the Lanczos method is frequently used for the 
diagonalization of the large matrices.
As explained in detail below,
one additional vector is necessary for
obtaining the eigenvector.

The principle of the Lanczos method is
based on the power method.
In the power method,
by successively operating the Hamiltonian $\Ham$ to the
arbitrary vector $\vec{x}_{0}$, we generate $\Ham^{n}\vec{x}_{0}$.
The obtained space 
$\mathcal{K}_{n+1}(\Ham,\vec{x}_{0})=\{\vec{x}_{0},\Ham^{1}\vec{x}_{0},\dots,\Ham^{n}\vec{x}_{0}\}$
is called the Krylov subspace.
The initial vector is represented by the superposition 
of the eigenvectors 
$\vec{e}_{i}$ (the corresponding eigenvalues are $E_{i}$) of $\Ham$ as 
\begin{align}
\vec{x}_{0}=\sum_{i}a_{i}\vec{e}_{i}.
\end{align}
Here, $E_{0}$ denotes the maximum absolute values of the eigenvalues.
We note that all the eigenvalues are real numbers because the Hamiltonian is Hermitian.
By operating $\Ham^{n}$ to the initial vector,
we obtain the relation as
\begin{align}
\Ham^{n}\vec{x}_{0}=E_{0}^{n}\Big[ a_{0}\vec{e}_{0}+\sum_{i\neq0}\left(\frac{E_{i}}{E_{0}}\right)^na_{i}\vec{e}_{i}\Big].
\end{align}
This relation indicates that
the eigenvector of $E_{0}$ becomes dominant for sufficiently large $n$. 
In the Lanczos method,
we obtain the eigenvalues and eigenvectors 
by performing the appropriate transformation for the obtained Krylov subspace.

In the Lanczos method,
we successively generate the normalized orthogonal basis 
${\vec{v}_{0},\dots,\vec{v}_{n-1}}$ from the Krylov subspace $\mathcal{K}_{n}(\Ham,\vec{x}_{0})$.
We define an initial vector and associated components as 
$\vec{v}_{0} =\vec{x}_{0}/|\vec{x}_{0}|$,
$\beta_{0}=0,\vec{x}_{-1}=0$.
From this initial condition,
we can obtain the normalized orthogonal basis:
\begin{align}
\alpha_{k} &= (\Ham\vec{v}_{k},\vec{v}_{k}), \\
\vec{w}   &= \Ham\vec{v}_{k}-\beta_{k}\vec{v}_{k-1}-\alpha_{k}\vec{v}_{k}, \\
\beta_{k+1} &= |\vec{w}|, \\
\vec{v}_{k+1} &= \frac{\vec{v}_{k}}{|\vec{v}_{k}|}. \label{eq: LanczosVector}
\end{align}
From these definitions, it it obvious that $\alpha_{k}$, $\beta_{k}$ are real numbers.

In the subspace spanned by these normalized orthogonal basis,
the Hamiltonian is transformed as
\begin{align}
T_{n}=V_{n}^{\dagger}\Ham V_{n}.
\end{align}
Here,
$V_{n}$ is a matrix whose column vectors are $\vec{v}_{i}(i=0,1,\dots,n-1)$.
$T_{n}$ is a tridiagonal matrix and its diagonal elements
are $\alpha_{i}$ and
subdiagonal elements are $\beta_{i}$.
It is known that
the eigenvalues of $\Ham$ are well approximated by 
the eigenvalues of $T_{n}$ for sufficiently large $n$.
(We note that $V^{\dagger}V=I$,$I$ is an identity matrix).
The original eigenvectors of $\Ham$ are obtained 
by $\vec{e}_{i}=V\tilde{\vec{e}}_{i}$,
where  $\tilde{\vec{e}}_{i}$ denotes
the eigenvectors of $T_{n}$.
From $V$, 
we can obtain the eigenvectors of $\Ham$
by performing the Lanczos method.
However, in the actual calculations,
it is difficult to keep $V$, because its dimension
is large [dimension of $V$ = (dimension of the total Hilbert space) $\times$ (the number of Lanczos iterations)].
Thus, to obtain the eigenvectors, 
we again perform the same Lanczos calculations
after we obtain the eigenvalues from the Lanczos methods.
In the first Lanczos calculation, we keep $\tilde{\vec{e}_{i}}$, 
because its dimension is small\footnote{Upper bound of the dimensions of $\tilde{\vec{e}_{i}}$ 
is $\#$ of Lanczos iterations.}.
From this procedure, we obtain the eigenvectors  from $V$.

In the Lanczos method,
within a few hundred or thousand Lanczos iterations,
we obtain accurate eigenvalues near the maximum and minimum eigenvalues.
The necessary number of iterations is sufficiently small as 
compared to the dimensions
of the total Hilbert space.
%Thus, the dimension of $T_{n}$ is 
%typically less than 100-1000.
We note that it is shown that
the errors of the maximum and minimum eigenvalues
become exponentially small as a function of Lanczos iterations 
(for details, see Ref.~\cite{SugiharaMurota_en}).

\subsection{Inverse iteration method}

From the approximate value of the eigenvalues ($E_{n}$),
by successively operating $(\Ham-E_{n})^{-1}$
to the initial vector $\vec{y}_{0}$,
we can obtain the accurate eigenvector for $E_{n}$.

From $(\Ham-E_{n})^{-1}\vec{y}_{0}$,
we obtain linear simultaneous equations such as  
\begin{align}
\vec{y}_{k}&=(\Ham-E_{n})\vec{y}_{k+1}. \label{eq: TPQVector}
\end{align}
By solving this equation using the
conjugate gradient method (CG method),
we obtain the eigenvector.
From the obtained eigenvector,
we can calculate the eigenvalues and correlation functions. 
We note that four additional vectors are necessary to
perform the CG method.
For a large system size,
it may be impossible to allocate memory to the
additional vectors.

\subsection{Details of implementation}
\subsubsection*{Initial vector}
For the Lanczos method, an initial vector is specified with \verb|initial_iv|($\equiv r_s$) defined in an input file for Standard mode or a ModPara file for Expert mode. The type of initial vector can be selected as a real number or complex number by using \verb|InitialVecType| in a ModPara file.
\begin{itemize}
\item{For canonical ensemble and \verb|initial_iv| $\geq 0$}

A component of a target of the Hilbert space is given by
\begin{align}
(N_{\rm dim}/2 + r_s ) \% N_{\rm dim},
\end{align}
where $N_{\rm dim}$ is the total number of the Hilbert spaces and $N_{\rm dim}/2$ is added to avoid selecting a special Hilbert space for a default value \verb|initial_iv| $=1$.  When the type of initial vector is selected as a real number, the coefficient value is given by $1$, while when it is selected as a complex number, the value is given by $(1+i)/\sqrt{2}$.

\item{For a grand canonical ensemble or \verb|initial_iv| $< 0$}

The initial vector is given by using a random generator, i.e., the coefficients of all the components for the initial vector are given by random numbers. The seed is calculated as 
\begin{align}
123432+|r_s|,
\end{align}
where $r_s$ is the number given by an input file and $n_{\rm run}$ is the number of runs. The maximum value of $n_{\rm run}$ is defined by \verb|NumAve| in an input file for Standard mode or a ModPara file for Expert mode. Random numbers are generated by using SIMD-oriented Fast Mersenne Twister (dSFMT)\cite{Mutsuo2008}. 
\end{itemize}

\subsubsection*{Convergence condition}
In $\HPhi$,
we use \verb|dsyev| (routine of LAPACK)
for diagonalization of $T_{n}$.
We use the energy of the first excited state of $T_{n}$
as the criterion of convergence. 
In the standard setting,
after five Lanczos steps,
we diagonalize $T_{n}$ every two Lanczos steps.
If the energy of the first excited states coincides with
the previous energy within the specified accuracy,
the Lanczos iteration finishes.
The accuracy of the convergence can be specified by 
$\verb|CDataFileHead|$~(ModPara file in the expert mode).

After obtaining the eigenvalues,
we again perform the Lanczos iteration
to obtain the eigenvector.
From the eigenvectors $|n\rangle$,
we calculate 
energy $E_{n}=\langle n|\Ham|n\rangle $ and
variance $\Delta=\langle n|\Ham^{2}|n\rangle -(\langle n|\Ham|n\rangle)^2$.
If $E_{n}$ coincides with the eigenvalues obtained by the Lanczos iteration and 
$\Delta$ is smaller than the specified value,
we finish diagonalization.

If the accuracy of the Lanczos method is not sufficient,
we perform the CG method to obtain the eigenvector.
As an initial vector of the CG method,
we use the eigenvectors obtained by the Lanczos method in the standard setting.
This frequently accelerates the convergence.
%----------------------------------------------------------
\section{Full Diagonalization method}
\label{Ch:AllDiagonalization}
\subsection{Overview}
We generate the matrix of ${\hat{H}}$ by using the real space configuration 
$| \psi_j \rangle$($j=1\cdots d_{\rm H}$, where $d_{\rm H}$ is the dimension of the Hilbert space): 
$H_{ij}= \langle \psi_i | {\hat H} | \psi_j \rangle$.
By diagonalizing this matrix,
we can obtain all the eigenvalues $E_{i}$ and eigenvectors $|\Phi_i\rangle$ ($i=1 \cdots d_{\rm H}$). 
In the diagonalization, we use a LAPACK routine, such as \verb|dsyev| or \verb|zheev|.
We also calculate and output
the expectation values $\la A_i\ra \equiv \langle \Phi_i | {\hat A} | \Phi_i\rangle$.
These values are used for the finite-temperature calculations.

\subsection{Finite-temperature calculations}
From
$\la A_i\ra \equiv \langle \Phi_i | {\hat A} | \Phi_i\rangle$,
we calculate the finite-temperature properties by using the relation 
\begin{equation}
\langle {\hat A}\rangle=\frac{\sum_{i=1}^N \la A_i\ra {\rm  e}^{-\beta E_i}}{\sum_{i=1}^N{\rm  e}^{-\beta E_i}}.
\end{equation}
The calculation should be performed by using the own postscripts.

%----------------------------------------------------------
\section{Finite-temperature calculations by the TPQ method}
\label{Ch:TPQ}
%----------------------------------------------------------
Sugiura and Shimizu showed that
it is possible to calculate the finite-temperature properties
from a few wavefunctions (in the thermodynamic limit, only one wave function is necessary)~\cite{Sugiura2012}.
The wavefunction is called the thermal pure quantum (TPQ) state.
Because the TPQ state can be generated by operating the Hamiltonian 
to the random initial wavefunction,
we directly use the routine Lanczos method for the TPQ calculations.
Here, we explain how to construct the micro canonical TPQ (mTPQ) state,
which offers the simplest method for calculating finite-temperature properties.

Let $|\psi_{0}\rangle$ be a random initial vector.
By operating $(l-\hat{H}/N_{s})^{k}$($l$ is constant and $N_{s}$ represents the number of sites) 
to $|\psi_{0}\rangle$,
we obtain the $k$th TPQ states as
\begin{align}
|\psi_{k}\rangle \equiv \frac{(l-\hat{H}/N_{s})|\psi_{k-1}\rangle}{|(l-\hat{H}/N_{s})|\psi_{k-1}\rangle|}.
\end{align}
From  $|\psi_{k}\rangle$, we estimate the corresponding inverse temperature $\beta_{k}$ as
\begin{align}
\beta_{k}\sim \frac{2k/N_{s}}{l-u_{k}},~~
u_{k} = \langle \psi_{k}|\hat{H}|\psi_{k}\rangle/N_{s},
\end{align}
where $u_{k}$ is the internal energy.
The arbitrary local physical properties at $\beta_{k}$ are also estimated as
\begin{align}
\langle \hat{A}\rangle_{\beta_{k}} =  \langle \psi_{k}|\hat{A}|\psi_{k}\rangle/N_{s}.
\end{align}

In a finite-size system,
error is caused by the choice of the initial random vector.
To estimate the average value and error of the physical properties,
we perform some independent calculations by changing $|\psi_{0}\rangle$.

\subsection{Details of implementation}
\subsubsection*{Initial vector}
For the TPQ method, the initial vector is given by using a random generator, i.e., the coefficients of all the components for the initial vector are given by random numbers. The seed is calculated as 
\begin{align}
123432+(n_{\rm run}+1)\times  |r_s|+k_{\rm Thread}+N_{\rm Thread} \times k_{\rm Process},
\end{align}
where $r_s$ is the number given by an input file and $n_{\rm run}$ is the number of runs. $r_s$ and the maximum value of $n_{\rm run}$ are defined by \verb|initial_iv| and \verb|NumAve| in an input file for Standard mode or a ModPara file for Expert mode, respectively. Random numbers are generated by using SIMD-oriented Fast Mersenne Twister (dSFMT)\cite{Mutsuo2008}. We can select the type of initial vector as a real number or complex number by using \verb|InitialVecType| in a ModPara file.
$k_{\rm Thread}, N_{\rm Thread}, and k_{\rm Process}$ indicate 
the thread ID, number of threads, process ID, respectively;
the initial vector depends both on \verb|initial_iv| and the number of parallelisms.

\section{\tr{Real time evolution method}}
\label{Ch:TE}
In ${\cal H}\Phi$, real time evolution calculation is done by using the following relation
\begin{equation}
|\Phi (t_n)\rangle = \exp^{-i {\cal H}  \Delta t_n}|\Phi (t_{n-1})\rangle,
\end{equation}
where $|\Phi(t_0)\rangle$ is an initial wave function and $t_n = \sum_{j=1}^n  \Delta t_j $.
In calculation, we approximate $\exp^{-i {\cal H}  \Delta t_n}$ as
\begin{equation}
\exp^{-i {\cal H}  \Delta t_n} =\sum_{l=0}^m \frac{1}{l!}(-i {\cal H}  \Delta t_n)^l .
\end{equation}
Here, the cut-off integer $m$ can be set by \verb|ExpandCoef| in \verb|ModPara|.
We can judge whether the expansion order is enough or not by checking the norm conservation $\langle \Phi (t_n)|\Phi (t_n)\rangle=1$ and energy conservation $\langle \Phi (t_n)|\hat{\cal H}|\Phi (t_n)\rangle=E$.

\section{Bogoliubov representation}\label{sec_bogoliubov_rep}

In the spin system,
the spin indices in the input files of \verb|transfer|, \verb|InterAll|,
and correlation functions are specified as those of the Bogoliubov representation.
The spin operators are written by using creation/annihilation operators:
\begin{align}
  S_{i z} &= \sum_{\sigma = -S}^{S} \sigma c_{i \sigma}^\dagger c_{i \sigma}
  \\
  S_{i}^+ &= \sum_{\sigma = -S}^{S-1} 
  \sqrt{S(S+1) - \sigma(\sigma+1)} 
  c_{i \sigma+1}^\dagger c_{i \sigma}
  \\
  S_{i}^- &= \sum_{\sigma = -S}^{S-1} 
  \sqrt{S(S+1) - \sigma(\sigma+1)} 
  c_{i \sigma}^\dagger c_{i \sigma+1}
\end{align}

%----------------------------------------------------------
